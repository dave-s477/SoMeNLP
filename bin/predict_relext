#!/usr/bin/env python

import os
import argparse
import json

from pathlib import Path

from somenlp.utils import str2bool
from somenlp.RE.run_relation_extraction import predict

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description = "")
    parser.add_argument("--input", required=None, help="Path to input file or directory.")
    parser.add_argument("--file-ext", default='.txt', help="How to select input files in case an input directory is provided.")
    parser.add_argument("--entity-ext", default='', help="Extension for entity files.")
    parser.add_argument("--prepro", default=True, type=str2bool, help="Apply input preprocessing pipeline (sentenization, tokenization, normalization, etc.)")
    parser.add_argument("--file-list", default=None, help="Provide a file list instead of going through a directory")
    parser.add_argument("--out-path", default='preds', help="Where to save results. If not provided results are only written to output console.")
    parser.add_argument("--out-ext", default='.rel-pred', help="Extension to append to output files.")
    parser.add_argument("--model-config", required=True, help="Full path to model configuration for training.")
    parser.add_argument("--bio-pred", action='store_true', help="Write output in form of BIO prediction for each input.")
    parser.add_argument("--offset", default=None, help="Offset number for prediction on large file list.")
    parser.add_argument("--limit", default=None, help="Limit of files to process when working on a large number of files")
    args = parser.parse_args()

    args.out_path = args.out_path.rstrip('/')
    if not os.path.isdir(args.out_path):
        os.makedirs(args.out_path)

    if args.file_list is None:
        in_path = Path(args.input)
        if in_path.is_file():
            print("Predicting file: {}".format(in_path))
            all_files = [{'in': in_path, 'entities': Path(str(in_path).replace(args.file_ext, args.entity_ext)), 'out': Path('{}/{}{}'.format(args.out_path, in_path.name, args.out_ext))}]
        elif in_path.is_dir():
            print("Predicting all files in folder: {}".format(in_path))
            all_files = sorted(list(in_path.rglob('*{}'.format(args.file_ext))), key=str)
            if args.offset is not None:
                offset = int(args.offset)
                print("Starting from offset {}".format(offset))
                all_files = all_files[offset:]
            if args.limit is not None:
                limit = int(args.limit)
                print("Limiting to {} articles".format(limit))
                all_files = all_files[:limit]

            all_files = [{'in': p, 'entities': Path(str(p).replace(args.file_ext, args.entity_ext)), 'out': Path(str(p).replace(args.input.rstrip('/'), args.out_path) + args.out_ext)} for p in all_files]
            print("Setting up output paths")
            subpaths = [str(entry['out']).rsplit('/', 1)[0] for entry in all_files]
            for p in subpaths:
                if not os.path.isdir(p):
                    os.makedirs(p)
        else:
            raise(RuntimeError("Input path does not exist: {}".format(in_path)))
    else:
        print("Predicting from file. Out-path is ignored and files are written to same directory.")
        with open(args.file_list, 'r') as j_in:
            all_files = json.load(j_in)
            all_files = [Path(p) for p in all_files]
        if args.offset is not None:
            offset = int(args.offset)
            print("Starting from offset {}".format(offset))
            all_files = all_files[offset:]
        if args.limit is not None:
            limit = int(args.limit)
            print("Limiting to {} articles".format(limit))
            all_files = all_files[:limit]

        all_files = [{'in': p, 'entities': Path(str(p).replace(args.file_ext, args.entity_ext)), 'out': Path(str(p) + args.out_ext)} for p in all_files]
        print("Setting up output paths")
        subpaths = [str(entry['out']).rsplit('/', 1)[0] for entry in all_files]
        for p in subpaths:
            if not os.path.isdir(p):
                os.makedirs(p)

    model_c_path = Path(args.model_config)
    if not model_c_path.is_file():
        raise(RuntimeError("Model configuration file does not exist"))
    with model_c_path.open(mode='r') as m_file:
        model_config = json.load(m_file)

    if 'checkpoint' not in model_config['general'].keys():
        raise(RuntimeError("Model Checkpoint has to be provided for prediction"))

    predict(model_config, all_files, args.prepro, args.bio_pred)
